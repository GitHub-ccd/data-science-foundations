{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set\n",
    "\n",
    "Something that we did not go over before was the validation set. We saw what a big difference in error we got with the test set, and we learned that we cannot trust the error we get on the training set. But the problem is that we cannot use the test set but once. So this would be fine if we were testing a single hypothesis, but this would not work if we were testing a series of different hypotheses against each other (consider KNN with K as 3 and 4). So what do we do?\n",
    "\n",
    "In practice we will split our data into three sets one used for training, one used to experiment on, and one to hold out until the end to test on. \n",
    "\n",
    "So what gives? We just showed that as we try multiple hypotheses the quality of the estimate decreases.\n",
    "\n",
    "Well as we just saw in the previous lesson and as we will see later on, when we train on data we will in general test infinite hypotheses. And in this case the error bound becomes far worse. \n",
    "\n",
    "So we have three data splits for three cases:\n",
    "\n",
    "1. Train data: we use this to test infinite hypotheses\n",
    "2. Validation data: we use this to test finite hypotheses\n",
    "3. Test data: we use this to test a single hypothesis\n",
    "\n",
    "Let's walk through doing this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we now consolidate the preprocessing\n",
    "def billionaire_preprocess():\n",
    "    data = pd.read_csv('../data/billionaires.csv')\n",
    "\n",
    "    del data['was founder']\n",
    "    del data['inherited']\n",
    "    del data['from emerging']\n",
    "\n",
    "    data.age.replace(-1, np.NaN, inplace=True)\n",
    "    data.founded.replace(0, np.NaN, inplace=True)\n",
    "    data.gdp.replace(0, np.NaN, inplace=True)\n",
    "    \n",
    "    del data['company.name']\n",
    "    del data['name']\n",
    "    del data['country code']\n",
    "    del data['citizenship']\n",
    "    del data['rank']\n",
    "    del data['relationship']\n",
    "    del data['sector']\n",
    "    \n",
    "    dummy_data = pd.get_dummies(data, dummy_na=True, columns=data.select_dtypes(exclude=['float64']), drop_first=True)\n",
    "    \n",
    "    return dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we get the data\n",
    "data = billionaire_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we parse out the target (this time classification)\n",
    "y = data['worth in billions'] > 2\n",
    "del data['worth in billions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we make our test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# and we make our validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1672, 70) (419, 70) (523, 70)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In practice\n",
    "\n",
    "So let's say that we wanted to try KNN, but we wanted to try multiple values for K, what could we do...\n",
    "\n",
    "In this case we would train multiple models and try them all on the validation set!\n",
    "\n",
    "First let's do some feature engineering (remember we only train our feature engineering on the training data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# We then consolidate the data munging code\n",
    "def billionaire_feature_eng(X, y, quantitative_pipeline, aggregated_pipeline, training=False):\n",
    "    data = X.copy()\n",
    "\n",
    "    qualitative_features = data.select_dtypes(exclude=['float64'])\n",
    "    quantitative_features = data.select_dtypes(include=['float64'])\n",
    "    \n",
    "    # notice how we only fit on the training data!\n",
    "    if training:\n",
    "        quant_X = quantitative_pipeline.fit_transform(quantitative_features)\n",
    "    else:\n",
    "        quant_X = quantitative_pipeline.transform(quantitative_features)\n",
    "\n",
    "    X = np.concatenate([quant_X, qualitative_features], axis=1)\n",
    "    \n",
    "    if training:\n",
    "        X = aggregated_pipeline.fit_transform(X, y)\n",
    "    else:\n",
    "        X = aggregated_pipeline.transform(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# and we can abstract out specific parts of the pipeline\n",
    "quantitative_pipeline = Pipeline([\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('standardize', StandardScaler()) \n",
    "])\n",
    "\n",
    "aggregated_pipeline = Pipeline([\n",
    "    ('var_threshold', VarianceThreshold(threshold=0.0)),\n",
    "    ('k_best', SelectKBest(mutual_info_classif, k=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = billionaire_feature_eng(X_train, y_train, quantitative_pipeline, aggregated_pipeline, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'company.type_new, privitization', u'gender_male',\n",
       "       u'industry_Diversified financial', u'region_South Asia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check out the features we are using\n",
    "data.columns[aggregated_pipeline.steps[0][1].get_support()][aggregated_pipeline.steps[1][1].get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# we can try 3, 4 and 5 for the number of neighbors\n",
    "cls = KNeighborsClassifier(n_neighbors=1, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55801435406698563"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.fit(X_train, y_train)\n",
    "\n",
    "# pretty bad accuracy, not the worst\n",
    "cls.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we try it on the validation data\n",
    "\n",
    "# first we do the feature eng on the validated data\n",
    "X_val, y_val = billionaire_feature_eng(X_val, y_val, quantitative_pipeline, aggregated_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45346062052505964"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57476076555\n",
      "0.491646778043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# we can try 3, 4 and 5 for the number of neighbors\n",
    "cls = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "\n",
    "cls.fit(X_train, y_train)\n",
    "\n",
    "print cls.score(X_train, y_train)\n",
    "\n",
    "print cls.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590909090909\n",
      "0.541766109785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# we can try 3, 4 and 5 for the number of neighbors\n",
    "cls = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "\n",
    "cls.fit(X_train, y_train)\n",
    "\n",
    "print cls.score(X_train, y_train)\n",
    "\n",
    "print cls.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
